---
title: "Coursera_Cleaning Data_ Week3"
output:
  pdf_document: default
  html_document: default
---
Subsetting and sorting 
```{r }
#Warm up
set.seed(13435)
X<- data.frame("var1"= sample(1:5),"var2"= sample(6:10),"var3"= sample(11:15))
X<- X[sample(1:5),] ; X$var2[c(1,3)]=NA
X


X[,1]
X[,"var1"]
X[["var1"]]

X[1:2, "var2"]

#subset with logical 
X[X$var1 <= 3 & X$var3 >11,]


X[X$var1 <= 3 | X$var3 >15,]


#Dealing with missing values: USe which

X[which(X$var2>8), ] #no  NA
X[X$var2>8, ]# with NA

#Sort

sort(X$var1)

sort(X$var1,decreasing = TRUE)

sort(X$var2,na.last = TRUE)


X[order(X$var1),]

#ordering with plyr

library(plyr)

arrange(X,var1)
arrange(X,desc(var1))


#adding rows and cols

X$var4 <- rnorm(5)
X
Y<- cbind(X, rnorm(5))
Y


```

Summarizing data 
```{r}
rest<- read.csv("/users/andrewhu/desktop/Coursera/Restaurants.csv")
#head(data)
#tail(data)
#str(data)
#quantile(data$var, na.rm=TRUE)
#quantile(data$var, probs=c(0.5,0.7,0.9))



#make a table
table(rest$zipCode, useNA="ifany") #not missing the NAs.

#two dimensional table
table(rest$councilDistrict, rest$zipCode)

#check for missing values

sum(is.na(rest$councilDistrict))

any(is.na(rest$councilDistrict))

colSums(is.na(rest))

all(colSums(is.na(rest))==0)


#finding values with specific characteristics

table(rest$zipCode %in% c("21212","21213"))


#use this logical var to subset

rest[rest$zipCode %in% c("21212","21213"),]

#Cross tabs
data(UCBAdmissions)
DF= as.data.frame(UCBAdmissions)
summary(DF)


x1<- xtabs(Freq~Gender+Admit, data=DF)
x1


#Flat tables
warpbreaks$replicate <- rep(1:9,len=54)
xt= xtabs(breaks~., data=warpbreaks)
xt

ftable(xt)
```


Creating new variables
```{r}
#Create sequences: need an index for data set
s1<- seq(1,10,by=2) ; s1 #specify the interval
s2<- seq(1,10,length=3) ; s2 #specify the length
x<- c(1,3,8,25,100); seq(along=x) #create index for the 5 values in x

#subsetting variables
rest$nearme = rest$neighborhood %in% c("Roland Park", "Homeland")

table(rest$nearme)

#Create binary variables
rest$zipWrong = ifelse(rest$zipCode<0, TRUE, FALSE)
table(rest$zipWrong, rest$zipCode<0)


#Create categorical variables
rest$zipGroups = cut(rest$zipCode, breaks= quantile(rest$zipCode))

table(rest$zipGroups)

table(rest$zipGroups, rest$zipCode)


#Easier cutting
library(Hmisc)
rest$zipGroups = cut2(rest$zipCode, g=4) #break them up according to the quantiles

table(rest$zipGroups)


#Create factor variables
rest$zcf <- factor(rest$zipCode)
rest$zcf[1:10]
class(rest$zcf)


#Levels of factor variables
yesno<- sample(c("yes", "no"), size=10, replace=TRUE)
yesnofac<- factor(yesno, levels= c("yes","no")) #default for levels is no
relevel(yesnofac, ref="yes")


#Mutate function: transform dataset 
library(Hmisc); library(plyr)
rest2 <- mutate(rest, zipGroups= cut2(zipCode,g=4))
table(rest2$zipGroups)



#common transforms

#abs(x) absolute value
#sqrt() square root
#ceiling 3.5 -->4
#floor 3.5 --> 3
#round(3.475,digits=2) is 3.48
#signif(3.475, digits=2) is 3.5


```




Data Reshaping: each var per col, each obs per row
```{r}
library(reshape2)
library(datasets)
head(mtcars)

#melt the dataset 

mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"), measure.vars=c("mpg","hp"))

head(carMelt, n=3)
tail(carMelt, n=3)


#Casting data frames

cylData <- dcast(carMelt, cyl~variable)# for cyl 4, there are 11 measurements for mpg..
cylData

cylData <- dcast(carMelt, cyl~variable,mean)
cylData


#Averaging values
head(InsectSprays)

#apply to count along the index spray, with sum
#sums up the count for each index spray
tapply(InsectSprays$count, InsectSprays$spray,sum)

#Another way using plyr package
ddply(InsectSprays, .(spray),summarise, sum=sum(count))
```



Intro to dplyr
```{r}
#Introduction to dplyr

library(dplyr)
chicago<- readRDS("/users/andrewhu/desktop/Coursera/chicago.rds")
dim(chicago)
str(chicago)

names(chicago)

#look at subsets of columns
head(select(chicago, city:dptp))
head(select(chicago, -(city:dptp)))


#filter
#subset using multiple conditions
chic.f <- filter(chicago, pm25tmean2>30 & tmpd>80)
head(chic.f)

#arrange: re order
chicago<- arrange(chicago,date)
head(chicago)
tail(chicago)

chicago<- arrange(chicago,desc(date))
head(chicago)


#rename (new name = old name)
chicago<- rename(chicago,pm25 = pm25tmean2, dewpoint=dptp)
head(chicago)

#Mutate:transform and create new var
chicago<- mutate(chicago, pm25detrend= pm25- mean(pm25,na.rm = TRUE))
head(chicago)


#group by: split a data frame according to categorical variables
chicago<- mutate(chicago, tempcat= factor(1* (tmpd>80), labels=c("cold","hot")))
hotcold<- group_by(chicago,tempcat)
hotcold

#summarize
summarize(hotcold, pm25=mean(pm25,na.rm=TRUE), o3=max(o3tmean2), no2= median(no2tmean2))


#summarize based on year
chicago<- mutate(chicago,year= as.POSIXlt(date)$year +1900)
years<- group_by(chicago,year)
summarize(years, pm25=mean(pm25,na.rm=TRUE), o3=max(o3tmean2), no2= median(no2tmean2))



#Pipeline operator
chicago %>% mutate(month = as.POSIXlt(date)$mon +1) %>% group_by(month) %>% summarize(pm25= mean(pm25, na.rm=TRUE), o3= max(o3tmean2), no2 = median(no2tmean2))

```


```{r}
#---------Merging data
review<- read.csv("/users/andrewhu/desktop/reviews.csv")
solu<- read.csv("/users/andrewhu/desktop/solutions.csv")


head(review)
head(solu)

names(review)
names(solu)

#merge by solution_id and id

mergedata= merge(review,solu,by.x="solution_id", by.y="id",all=TRUE)
head(mergedata)


#use plyr to merge

#e.g. arrange(join(df1,df2),id)


#Multiple dfs

df1 = data.frame(id=sample(1:10),x=rnorm(10))
df2 = data.frame(id=sample(1:10),y=rnorm(10))
df3 = data.frame(id=sample(1:10),z=rnorm(10))
dfList <- list(df1,df2,df3)
join_all(dfList)







```